#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
Job Classification Prediction Script

Ø§Ø³ØªØ®Ø¯Ø§Ù…:
python predict_job.py
"""

import pickle
import re
import os
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import nltk

# ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª NLTK
try:
    nltk.download('stopwords', quiet=True)
    nltk.download('punkt', quiet=True)
    nltk.download('wordnet', quiet=True)
    nltk.download('omw-1.4', quiet=True)
except:
    print("ØªØ­Ø°ÙŠØ±: Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª NLTK ÙŠØ¯ÙˆÙŠØ§Ù‹")

def load_model():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª"""
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        with open("best_classifier.pkl", "rb") as file:
            classifier = pickle.load(file)
        
        # ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù†ØµÙˆØµ
        with open("features_extractor.pkl", "rb") as file:
            features_extractor = pickle.load(file)
        
        # ØªØ­Ù…ÙŠÙ„ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙØ¦Ø§Øª (Ø¥Ù† ÙˆØ¬Ø¯)
        try:
            with open("category_mapping.pkl", "rb") as file:
                category_mapping = pickle.load(file)
        except:
            category_mapping = None
        
        print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
        return classifier, features_extractor, category_mapping
    
    except FileNotFoundError as e:
        print(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        print("ÙŠØ±Ø¬Ù‰ ØªØ´ØºÙŠÙ„ Jobs_Classifiers_Fixed.py Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
        return None, None, None
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        return None, None, None

# Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ (Ù†ÙØ³ Ø§Ù„Ø¯ÙˆØ§Ù„ Ù…Ù† Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ)
def remove_tags(text):
    """Ø¥Ø²Ø§Ù„Ø© HTML tags"""
    if not text:
        return ""
    remove = re.compile(r'<.*?>')
    return re.sub(remove, '', str(text))

def special_char(text):
    """Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ©"""
    if not text:
        return ""
    result = ''
    for char in str(text):
        if char.isalnum():
            result += char
        else:
            result += ' '
    return result

def convert_lower(text):
    """ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©"""
    if not text:
        return ""
    return str(text).lower()

def remove_stopwords(text):
    """Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ÙˆÙ‚Ù"""
    if not text:
        return []
    try:
        stop_words = set(stopwords.words('english'))
        words = word_tokenize(str(text))
        return [word for word in words if word not in stop_words and len(word) > 2]
    except:
        return str(text).split()

def lemmatize_word(words):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø°ÙˆØ± Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
    if not words:
        return ""
    try:
        wordnet = WordNetLemmatizer()
        if isinstance(words, list):
            return " ".join([wordnet.lemmatize(word) for word in words])
        else:
            return str(words)
    except:
        if isinstance(words, list):
            return " ".join(words)
        return str(words)

def preprocess_text(text):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    if not text:
        return ""
    
    text = remove_tags(text)
    text = special_char(text)
    text = convert_lower(text)
    text = remove_stopwords(text)
    text = lemmatize_word(text)
    return text

def predict_job_category(job_description, classifier, features_extractor):
    """ØªØµÙ†ÙŠÙ ÙˆØµÙ Ø§Ù„ÙˆØ¸ÙŠÙØ©"""
    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ
        processed_text = preprocess_text(job_description)
        
        if not processed_text:
            return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯", 0
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ features
        text_features = features_extractor.transform([processed_text])
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        prediction = classifier.predict(text_features)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ§Øª Ø§Ù„ØªØµÙ†ÙŠÙ
        try:
            probabilities = classifier.predict_proba(text_features)
            confidence = max(probabilities[0]) * 100
        except:
            confidence = 0
        
        return prediction[0], confidence
    
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ: {e}")
        return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯", 0

def display_categories():
    """Ø¹Ø±Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©"""
    categories = [
        "1. Pharmaceutical, Healthcare and Medical Sales",
        "2. Clinical Research",
        "3. Pharmaceutical Marketing", 
        "4. Manufacturing & Operations",
        "5. Science",
        "6. Medical Affairs / Pharmaceutical Physician",
        "7. Regulatory Affairs",
        "8. Medical Information and Pharmacovigilance",
        "9. Data Management and Statistics",
        "10. Quality-assurance",
        "11. Pharmacy"
    ]
    
    print("\nğŸ“‹ ÙØ¦Ø§Øª Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØªØ§Ø­Ø©:")
    print("=" * 50)
    for category in categories:
        print(f"   {category}")
    print("=" * 50)

def run_examples(classifier, features_extractor):
    """ØªØ´ØºÙŠÙ„ Ø£Ù…Ø«Ù„Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©"""
    test_jobs = [
        "responsible for clinical trials and patient recruitment in pharmaceutical research",
        "marketing manager for pharmaceutical products and medical devices", 
        "quality assurance specialist ensuring compliance with FDA regulations",
        "sales representative for medical equipment and pharmaceutical products",
        "data analyst responsible for statistical analysis of clinical trial results",
        "regulatory affairs manager preparing drug submissions to health authorities",
        "pharmacist dispensing medications and providing patient counseling",
        "manufacturing engineer optimizing pharmaceutical production processes"
    ]
    
    print("\n=== Ø£Ù…Ø«Ù„Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ© ===")
    print("=" * 60)
    
    for i, job in enumerate(test_jobs, 1):
        category, confidence = predict_job_category(job, classifier, features_extractor)
        print(f"\n{i}. Ø§Ù„ÙˆØµÙ:")
        print(f"   {job}")
        print(f"   ğŸ¯ Ø§Ù„ØªØµÙ†ÙŠÙ: {category}")
        print(f"   ğŸ“Š Ø§Ù„Ø«Ù‚Ø©: {confidence:.1f}%")
        print("-" * 60)

def interactive_mode(classifier, features_extractor):
    """Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ"""
    print("\n=== Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ ===")
    print("ğŸ’¡ Ù†ØµØ§Ø¦Ø­:")
    print("   - Ø£Ø¯Ø®Ù„ ÙˆØµÙ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©")
    print("   - ÙƒÙ† Ù…Ø­Ø¯Ø¯Ø§Ù‹ ÙÙŠ Ø§Ù„ÙˆØµÙ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„")
    print("   - Ø§ÙƒØªØ¨ 'exit' Ø£Ùˆ 'quit' Ù„Ù„Ø®Ø±ÙˆØ¬")
    print("   - Ø§ÙƒØªØ¨ 'examples' Ù„Ø±Ø¤ÙŠØ© Ø£Ù…Ø«Ù„Ø©")
    print("   - Ø§ÙƒØªØ¨ 'categories' Ù„Ø±Ø¤ÙŠØ© Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©")
    print("=" * 60)
    
    while True:
        try:
            user_input = input("\nğŸ“ Ø£Ø¯Ø®Ù„ ÙˆØµÙ Ø§Ù„ÙˆØ¸ÙŠÙØ©: ").strip()
            
            if user_input.lower() in ['exit', 'quit', 'Ø®Ø±ÙˆØ¬', 'q']:
                print("ğŸ‘‹ Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØµÙ†Ù Ø§Ù„ÙˆØ¸Ø§Ø¦Ù!")
                break
            
            elif user_input.lower() in ['examples', 'Ø£Ù…Ø«Ù„Ø©']:
                run_examples(classifier, features_extractor)
                continue
            
            elif user_input.lower() in ['categories', 'ÙØ¦Ø§Øª']:
                display_categories()
                continue
            
            elif user_input.lower() in ['help', 'Ù…Ø³Ø§Ø¹Ø¯Ø©']:
                print("\nğŸ“š Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©:")
                print("   - examples: Ø¹Ø±Ø¶ Ø£Ù…Ø«Ù„Ø© ØªØ¬Ø±ÙŠØ¨ÙŠØ©")
                print("   - categories: Ø¹Ø±Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©")
                print("   - help: Ø¹Ø±Ø¶ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©")
                print("   - exit/quit: Ø§Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬")
                continue
            
            elif not user_input:
                print("âš ï¸  ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ ÙˆØµÙ Ù„Ù„ÙˆØ¸ÙŠÙØ©")
                continue
            
            # ØªØµÙ†ÙŠÙ Ø§Ù„ÙˆØ¸ÙŠÙØ©
            category, confidence = predict_job_category(user_input, classifier, features_extractor)
            
            print(f"\nğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø©:")
            print(f"   Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: {category}")
            print(f"   Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {confidence:.1f}%")
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø«Ù‚Ø©
            if confidence >= 90:
                print("   âœ… Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§